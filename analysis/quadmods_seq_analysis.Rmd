---
title: "Quadrilateral learning experiments: Sequences"
author: "Kyle MacDonald and Michael Frank"
date: "January 22, 2016"
output: html_document
---

```{r, echo = F}
rm(list=ls()) # clear workspace
knitr::opts_chunk$set(warning=FALSE, message=FALSE, sanitize = T, 
                      fig.height=4, fig.width=7, echo=F, cache = T)
```

```{r prelims}
library(langcog)
library(dplyr)
library(ggplot2)
library(tidyr)
library(binom)
library(lme4)
library(bootstrap)
library(magrittr)
library(stringr)
theme_set(theme_bw())
```

```{r}
## for bootstrapping 95% confidence intervals
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}
```

Load data.

```{r data_clean}
d1 <- read.csv("../data/quadmods-sequences-pilot.csv", header=TRUE, 
               row.names=NULL, stringsAsFactors = FALSE)

d1$block <- factor(d1$block, levels = c("pretest", "posttest"))
```

Descriptives
--------

### How many participants in each condition?

```{r}
d1 %>% 
    select(subids, training_condition) %>% 
    unique() %>% 
    group_by(training_condition) %>% 
    summarise(n())
```

### How long did each condition take?

```{r}
d1 %>% 
    group_by(training_condition) %>% 
    summarise(m_train_time = (mean(training_time) / 1000) / 60,
              m_exp_time = (mean(exp_time) / 1000) / 60)
```

```{r}
ss <- d1 %>% 
    distinct(subids) %>% 
    mutate(train_time_min = (training_time / 1000) / 60,
              exp_time_min = (exp_time / 1000) / 60)

ggplot(aes(x=exp_time_min), data = ss) +
    geom_histogram(binwidth = 0.2) +
    facet_grid(.~training_condition) 
```

Visualization
--------

### Relational pretest broken down by question and condition

```{r, fig.width=9, fig.height=6}
ms <- d1 %>% 
  filter(trial_type %in% c("relational")) %>%
  group_by(question_and_shape, question, block, training_condition) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question_and_shape, y = m, fill = question), data = ms) + 
    geom_bar(stat="identity") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih)) +
    geom_hline(yintercept = .5, lty = 2) +
    ylim(0, 1) + 
    facet_grid(training_condition~block) +
    scale_fill_solarized() +
    theme(axis.text.x = element_text(angle = 65, hjust = 1)) +
    ggtitle("Accuracy on each question: Relational Test")
```

Seems reasonable -- participants are performing above chance for most questions. 

The hardest questions were:

* Is a parallelogram and rectangle?
* Is a square a rhombus?

But participants get worse after training? 

### Sanity check on entity pretest for all 16 question_shape combinations 

```{r, fig.width = 9, fig.height=6}
ms <- d1 %>% 
  filter(trial_type %in% c("entity")) %>%
  group_by(question_and_shape, question, training_condition, block) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question_and_shape, y = m, fill = question), data = ms) + 
    geom_bar(stat="identity") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih)) +
    ylim(0, 1) + 
    facet_grid(training_condition~block) +
    scale_fill_solarized() +
    theme(axis.text.x = element_text(angle = 65, hjust = 1)) +
    ggtitle("Accuracy on each question: Entity Test")
```

- People are good at selecting the shape we ask for: PaPa, ReRe, RhRh, SqSq.
- They are not likely to select other shapes for parallelograms or squares.
- There is more disagreement between ss about rectangles and rhombi.
- For rectangles, people also select rhombi.
- For rhombi, people select rectangles.

### Sanity check on entity pretest for shape questions

```{r, fig.width = 6, fig.height=4}
ms <- d1 %>% 
  filter(trial_type %in% c("entity")) %>%
  group_by(question, block) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question, y = m), data = ms) + 
    geom_bar(stat="identity") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih)) +
    ylim(0, 1) + 
    facet_grid(.~block) +
    theme(axis.text.x = element_text(angle = 65, hjust = 1)) +
    ggtitle("Accuracy on each shape: Entity Test")
```

How do we define chance performance on the entity test? Chance level changes for each question:

- Rectangle: 2/4 are rectangles
- Parallelogram: 4/4 are paralleograms
- Square: 1/4 are squares
- Rhombus: 2/4 are rhombi

### Overall accuracy analysis for both entity and relational tests

```{r}
ms <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(training_condition, trial_type, block = as.factor(block)) %>%
    summarise(m_acc = mean(correct),
              m.cih = ci.high(correct),
              m.cil = ci.low(correct))

ms %<>% mutate(chance_line = ifelse(trial_type == "relational", 0.5, 0.5))

ggplot(aes(x = block, y = m_acc, color = training_condition), data = ms) +
    geom_pointrange(aes(ymin = m_acc - m.cil, ymax = m_acc + m.cih)) +
    geom_line(aes(group=training_condition)) +
    geom_hline(aes(yintercept = chance_line), linetype = "dashed") +
    ylim(0.4,1.0) +
    facet_grid(.~trial_type) +
    scale_color_solarized() 
```

### Within subjects change scores all shapes

```{r}
ss_acc <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m_acc = mean(correct)) %>% 
    spread(key = block, value = m_acc) %>% 
    mutate(m_diff_score = posttest - pretest)

ms_change <- ss_acc %>% 
    group_by(training_condition, trial_type) %>% 
    summarise(m_change_score = mean(m_diff_score),
              m.cih = ci.high(m_diff_score),
              m.cil = ci.low(m_diff_score))

ggplot(aes(x = training_condition, y = m_change_score, fill = training_condition), 
       data = ms_change) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m_change_score - m.cil, ymax = m_change_score + m.cih)) +
    geom_hline(yintercept = 0) +
    facet_grid(.~trial_type) +
    scale_fill_solarized() +
    ylim(-0.45, 0.45) + 
    guides(fill=F)
```

## Accuracy on the learned shape

```{r}
d_shape_learned <- filter(d1, question == shape_learned | shape == shape_learned)
```

### Overall accuracy analysis for both entity and relational tests

```{r}
ms_shape <- d_shape_learned %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(training_condition, trial_type, block = as.factor(block)) %>%
    summarise(m_acc = mean(correct),
              m.cih = ci.high(correct),
              m.cil = ci.low(correct))

ms_shape$block <- factor(ms_shape$block, levels = c("pretest", "posttest"))
ms_shape %<>% mutate(chance_line = ifelse(trial_type == "relational", 0.5, 0.5))

ggplot(aes(x = block, y = m_acc, color = training_condition), data = ms_shape) +
    geom_pointrange(aes(ymin = m_acc - m.cil, ymax = m_acc + m.cih)) +
    geom_line(aes(group=training_condition)) +
    geom_hline(aes(yintercept = chance_line), linetype = "dashed") +
    ylim(0.4,1.0) +
    facet_grid(.~trial_type) +
    scale_color_solarized()
```

### Within subjects change scores for learned shape tests

```{r}
ss_acc_learned <- d_shape_learned %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m_acc = mean(correct)) %>% 
    spread(key = block, value = m_acc) %>% 
    mutate(m_diff_score = posttest - pretest)

ms_change_learned <- ss_acc_learned %>% 
    group_by(training_condition, trial_type) %>% 
    summarise(m_change_score = mean(m_diff_score),
              m.cih = ci.high(m_diff_score),
              m.cil = ci.low(m_diff_score))

ggplot(aes(x = training_condition, y = m_change_score, fill = training_condition), 
       data = ms_change_learned) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m_change_score - m.cil, ymax = m_change_score + m.cih)) +
    geom_hline(yintercept = 0) +
    facet_grid(.~trial_type) +
    scale_fill_solarized() +
    ylim(-0.4, 0.4) + 
    guides(fill=F)
```

Models (todo)
-------

### Predict overall accuracy based on condition and test type

```{r, eval = F}
mm1 <- glmer(correct ~ training_condition * trial_type * block + (1|subids),
             data = filter(d1, trial_type %in% c("relational", "entity")),
             family=binomial, 
             nAGQ = 1,
             control = glmerControl(optimizer = "bobyqa"))
summary(mm1)
```

### Predict accuracy for learned shape based on condition and test type

```{r, eval = F}
mm2 <- glmer(correct ~ training_condition * block * trial_type + (1|subids) ,
             data = filter(d_shape_learned, trial_type %in% c("relational", "entity")),
             family=binomial, 
             nAGQ = 1,
             control = glmerControl(optimizer = "bobyqa"))
summary(mm2)
```

### Predict change scores for learned shape based on condition and test type

```{r, eval = F}
mm3 <- lmer(m_diff_score ~ training_condition * trial_type + (1|subids) ,
             data = ss_acc_learned)
summary(mm3)
```

Exploratory Analyses
--------------------

### Look at individual participants

```{r}
ss_m <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m = mean(correct))

ggplot(aes(x = block, y = m, color = training_condition, group = as.factor(subids)), data = ss_m) +
    geom_point() +
    geom_line() +
    geom_jitter(width = 0.2) +
    facet_grid(.~trial_type) +
    scale_color_solarized() 
```

### Training time distribution for each condition

```{r}
ggplot(aes(x = train_time_min), data = ss) +
    geom_histogram() +
    facet_grid(.~training_condition)
```

Median split on training time for active learning

```{r}
ss %<>% mutate(active_learner_pace = cut(train_time_min, 2, labels = c("fast", "slow")))
```