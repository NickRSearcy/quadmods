---
title: "Quadrilateral learning experiments: Sequences"
author: "Kyle MacDonald and Michael Frank"
date: "January 22, 2016"
output: html_document
---

```{r, echo = F}
rm(list=ls()) # clear workspace
knitr::opts_chunk$set(warning=FALSE, message=FALSE, sanitize = T, 
                      fig.height=4, fig.width=7, echo=F, cache = T)
```

```{r prelims}
library(langcog)
library(dplyr)
library(ggplot2)
library(tidyr)
library(binom)
library(lme4)
library(bootstrap)
library(magrittr)
library(stringr)
theme_set(theme_bw())
```

```{r}
## for bootstrapping 95% confidence intervals
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}
```

Load data.

```{r data_clean}
d1 <- read.csv("../data/quadmods-sequences-exp1_2.csv", header=TRUE, 
               row.names=NULL, stringsAsFactors = FALSE)
```

```{r}
d1$block <- factor(d1$block, levels = c("pretest", "posttest"))
```

Descriptives
--------

### How many participants in each condition?

```{r}
d1 %>% 
    select(subids, training_condition) %>% 
    unique() %>% 
    group_by(training_condition) %>% 
    summarise(n())
```

### How long did each condition take?

```{r}
d1 %>% 
    group_by(training_condition) %>% 
    summarise(m_train_time = (mean(training_time) / 1000) / 60,
              m_exp_time = (mean(exp_time) / 1000) / 60)
```

```{r}
ss <- d1 %>% 
    distinct(subids) %>% 
    mutate(train_time_min = (training_time / 1000) / 60,
              exp_time_min = (exp_time / 1000) / 60)

ggplot(aes(x=train_time_min), data = ss) +
    geom_histogram(binwidth = 0.1) +
    facet_grid(.~training_condition) 
```

### SS level filtering analysis

Remove:
- Participants who were scored perfect on the pretest
- Participants who's difference scores were 3 SD away from the mean difference score

```{r}
ss_diff_scores <- d1 %>% 
    filter(trial_type %in% c("relational","entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest)

ms <- ss_diff_scores %>% 
    group_by(training_condition, trial_type) %>% 
    summarise(stdev_diff = sd(tot_diff_score),
              mean_diff = mean(tot_diff_score))

ss_diff_scores <- left_join(ss_diff_scores, ms)

# create filter based on sd from mean difference score
filter_ss <- function (diff_score, stdev_diff, mean_diff) {
    if (diff_score >= mean_diff + (2*stdev_diff) | diff_score <= mean_diff - (2*stdev_diff)) {
        remove <- "yes"
    } else {
        remove <- "no"
    }
    remove
}

ss_diff_scores <- ss_diff_scores %>% 
    rowwise() %>% 
    mutate(remove = filter_ss(diff_score = tot_diff_score, stdev_diff = stdev_diff, mean_diff = mean_diff))

# merge filter info with rest of data
d1 <- ss_diff_scores %>% 
    select(subids, remove) %>% 
    left_join(d1, .)
```

```{r}
d1 <- filter(d1, remove == "no")
```


Visualization
--------

### Relational pretest broken down by question and condition

```{r, fig.width=9, fig.height=6}
ms <- d1 %>% 
  filter(trial_type %in% c("relational")) %>%
  group_by(question_and_shape, question, block, training_condition) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question_and_shape, y = m, fill = block), data = ms) + 
    geom_bar(stat="identity", position="dodge") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih),  position = position_dodge(width = 0.9)) +
    geom_hline(yintercept = .5, lty = 2) +
    ylim(0, 1) + 
    facet_grid(training_condition~.) +
    scale_fill_solarized() +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    ggtitle("Accuracy on each question: Relational Test")
```

### Sanity check on entity pretest for all 16 question_shape combinations 

```{r, fig.width = 9, fig.height=6}
ms <- d1 %>% 
  filter(trial_type %in% c("entity")) %>%
  group_by(question_and_shape, question, training_condition, block) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question_and_shape, y = m, fill = block), data = ms) + 
    geom_bar(stat="identity", position="dodge") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih),  position = position_dodge(width = 0.9)) +
    ylim(0, 1) + 
    facet_grid(training_condition~.) +
    scale_fill_solarized() +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    ggtitle("Accuracy on each question: Entity Test")
```

### Sanity check on entity pretest for shape questions

```{r, fig.width = 6, fig.height=4}
ms <- d1 %>% 
  filter(trial_type %in% c("entity")) %>%
  group_by(question, block) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question, y = m), data = ms) + 
    geom_bar(stat="identity") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih)) +
    ylim(0, 1) + 
    facet_grid(.~block) +
    theme(axis.text.x = element_text(angle = 65, hjust = 1)) +
    ggtitle("Accuracy on each shape: Entity Test")
```

How do we define chance performance on the entity test? Chance level changes for each question:

- Rectangle: 2/4 are rectangles
- Parallelogram: 4/4 are paralleograms
- Square: 1/4 are squares
- Rhombus: 2/4 are rhombi

### Overall accuracy analysis for both entity and relational tests

```{r}
ms <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(training_condition, trial_type, block = as.factor(block)) %>%
    summarise(m_acc = mean(correct),
              m.cih = ci.high(correct),
              m.cil = ci.low(correct))

ms %<>% mutate(chance_line = ifelse(trial_type == "relational", 0.5, 0.5))

ggplot(aes(x = block, y = m_acc, color = training_condition), data = ms) +
    geom_pointrange(aes(ymin = m_acc - m.cil, ymax = m_acc + m.cih)) +
    geom_line(aes(group=training_condition)) +
    geom_hline(aes(yintercept = chance_line), linetype = "dashed") +
    ylim(0.4,1.0) +
    facet_grid(.~trial_type) +
    scale_color_solarized() 
```

### Within subjects change scores all shapes

```{r}
ss_acc <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m_acc = mean(correct)) %>% 
    spread(key = block, value = m_acc) %>% 
    mutate(m_diff_score = posttest - pretest)

ms_change <- ss_acc %>% 
    group_by(training_condition, trial_type) %>% 
    summarise(m_change_score = mean(m_diff_score),
              m.cih = ci.high(m_diff_score),
              m.cil = ci.low(m_diff_score))

ggplot(aes(x = training_condition, y = m_change_score, fill = training_condition), 
       data = ms_change) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m_change_score - m.cil, ymax = m_change_score + m.cih)) +
    geom_hline(yintercept = 0) +
    facet_grid(.~trial_type) +
    scale_fill_solarized() +
    ylim(-0.1, 0.1) + 
    theme(axis.text.x = element_text(angle = 65, hjust = 1)) +
    guides(fill=F)
```

## Accuracy on the learned shape

```{r}
d_shape_learned <- filter(d1, question == shape_learned | shape == shape_learned)
```

### Relational tests for learned shape

```{r, fig.width=9, fig.height=6}
ms <- d_shape_learned %>% 
  filter(trial_type %in% c("relational")) %>%
  group_by(question_and_shape, question, block, training_condition) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question_and_shape, y = m, fill = block), data = ms) + 
    geom_bar(stat="identity", position="dodge") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih),  position = position_dodge(width = 0.9)) +
    geom_hline(yintercept = .5, lty = 2) +
    ylim(0, 1) + 
    facet_grid(training_condition~.) +
    scale_fill_solarized() +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    ggtitle("Accuracy on each question: Relational Test")
```

### entity tests for learned shape

```{r, fig.width = 9, fig.height=6}
ms <- d_shape_learned %>% 
  filter(trial_type %in% c("entity")) %>%
  group_by(question_and_shape, question, training_condition, block) %>%
  summarise(m.cih = ci.high(correct),
            m.cil = ci.low(correct),
            m = mean(correct))

ggplot(aes(x = question_and_shape, y = m, fill = block), data = ms) + 
    geom_bar(stat="identity", position="dodge") +
    geom_linerange(aes( ymin = m - m.cil, ymax = m + m.cih),  position = position_dodge(width = 0.9)) +
    ylim(0, 1) + 
    facet_grid(training_condition~.) +
    scale_fill_solarized() +
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    ggtitle("Accuracy on each question: Entity Test")
```


### Overall accuracy analysis for both entity and relational tests

```{r}
ms_shape <- d_shape_learned %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(training_condition, trial_type, block = as.factor(block)) %>%
    summarise(m_acc = mean(correct),
              m.cih = ci.high(correct),
              m.cil = ci.low(correct))

ms_shape$block <- factor(ms_shape$block, levels = c("pretest", "posttest"))
ms_shape %<>% mutate(chance_line = ifelse(trial_type == "relational", 0.5, 0.5))

ggplot(aes(x = block, y = m_acc, color = training_condition), data = ms_shape) +
    geom_pointrange(aes(ymin = m_acc - m.cil, ymax = m_acc + m.cih)) +
    geom_line(aes(group=training_condition)) +
    geom_hline(aes(yintercept = chance_line), linetype = "dashed") +
    ylim(0.4,1.0) +
    facet_grid(.~trial_type) +
    scale_color_solarized()
```

### Within subjects change scores for learned shape tests

```{r}
ss_acc_learned <- d_shape_learned %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m_acc = mean(correct)) %>% 
    spread(key = block, value = m_acc) %>% 
    mutate(m_diff_score = posttest - pretest)

ms_change_learned <- ss_acc_learned %>% 
    group_by(training_condition, trial_type) %>% 
    summarise(m_change_score = mean(m_diff_score),
              m.cih = ci.high(m_diff_score),
              m.cil = ci.low(m_diff_score))

ggplot(aes(x = training_condition, y = m_change_score, fill = training_condition), 
       data = ms_change_learned) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m_change_score - m.cil, ymax = m_change_score + m.cih)) +
    geom_hline(yintercept = 0) +
    facet_grid(.~trial_type) +
    scale_fill_solarized() +
    ylim(-0.15, 0.15) + 
    guides(fill=F)
```

Models (todo)
-------

### Predict overall accuracy based on condition and test type

```{r, eval = F}
mm1 <- glmer(correct ~ training_condition * block + (1|subids),
             data = filter(d1, trial_type %in% c("relational", "entity")),
             family=binomial, 
             nAGQ = 1,
             control = glmerControl(optimizer = "bobyqa"))
summary(mm1)
```

### Predict accuracy for learned shape based on condition and test type

```{r, eval = F}
mm2 <- glmer(correct ~ training_condition * block * trial_type + (1|subids) ,
             data = filter(d_shape_learned, trial_type %in% c("relational", "entity")),
             family=binomial, 
             nAGQ = 1,
             control = glmerControl(optimizer = "bobyqa"))
summary(mm2)
```

### Predict change scores for learned shape based on condition and test type

```{r, eval = F}
lm1 <- lm(m_diff_score ~ training_condition * trial_type,data = ss_acc)
summary(lm1)
```

Exploratory Analyses
--------------------

### Look at individual participants

```{r}
ss_m <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m = mean(correct))

ggplot(aes(x = block, y = m, color = training_condition, group = as.factor(subids)), data = ss_m) +
    geom_point() +
    geom_line() +
    facet_grid(training_condition~trial_type) +
    scale_color_solarized() 
```

### Training time distribution for each condition

```{r}
ggplot(aes(x = train_time_min), data = ss) +
    geom_histogram() +
    facet_grid(.~training_condition)
```

Median split on training time for active learning

```{r}
ss %<>% mutate(active_learner_pace = cut(train_time_min, 2, labels = c("fast", "slow")))
```


### Overall accuracy analysis collapsing across entity and relational tests shape learned

```{r}
ms <- d1 %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(training_condition, block = as.factor(block)) %>% 
     summarise(m_acc = mean(correct),
              m.cih = ci.high(correct),
              m.cil = ci.low(correct))

ggplot(aes(x = block, y = m_acc, color = training_condition), data = ms) +
    geom_pointrange(aes(ymin = m_acc - m.cil, ymax = m_acc + m.cih)) +
    geom_line(aes(group=training_condition)) +
    ylim(0.4,0.9) +
    scale_color_solarized() 
```

### Overall accuracy for shape learned collapsing across tests

```{r}
ms <- d_shape_learned %>% 
    filter(trial_type %in% c("relational", "entity")) %>% 
    group_by(training_condition, block = as.factor(block)) %>% 
     summarise(m_acc = mean(correct),
              m.cih = ci.high(correct),
              m.cil = ci.low(correct))

ggplot(aes(x = block, y = m_acc, color = training_condition), data = ms) +
    geom_pointrange(aes(ymin = m_acc - m.cil, ymax = m_acc + m.cih)) +
    geom_line(aes(group=training_condition)) +
    ylim(0.4,0.9) +
    scale_color_solarized() 
```

### Total difference score analysis

```{r}
ss <- d1 %>% 
    filter(trial_type %in% c("relational","entity")) %>% 
    group_by(subids, training_condition, block) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest)

ms <- ss %>% 
    group_by(training_condition) %>% 
    summarise(m = mean(tot_diff_score),
              ci_h = ci.high(tot_diff_score),
              ci_l = ci.low(tot_diff_score))
```

Plot

```{r}
ggplot(aes(x = training_condition, y = m, fill = training_condition), data = ms) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m - ci_l, ymax = m + ci_h)) +
    geom_hline(yintercept = 0) +
    guides(fill=F) +
    scale_fill_solarized() +
    ylim(-0.2, 0.2)
```

Dotplot

```{r}
ggplot(aes(x = training_condition, y = tot_diff_score, fill = training_condition), data = ss) +
    geom_dotplot(binaxis = "y", stackdir = "center") +
    scale_fill_solarized() +
    guides(fill=F)
```

Model 

```{r}
lm2 <- lm(tot_diff_score ~ training_condition, data = ss)
summary(lm2)
```

### Total difference score analysis for learned shape

```{r}
ss <- d_shape_learned %>% 
    filter(trial_type %in% c("relational","entity")) %>% 
    group_by(subids, training_condition, block) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest)

ms <- ss %>% 
    group_by(training_condition) %>% 
    summarise(m = mean(tot_diff_score),
              ci_h = ci.high(tot_diff_score),
              ci_l = ci.low(tot_diff_score))
```

Plot

```{r}
ggplot(aes(x = training_condition, y = m, fill = training_condition), data = ms) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m - ci_l, ymax = m + ci_h)) +
    geom_hline(yintercept = 0) +
    guides(fill=F) +
    scale_fill_solarized() +
    ylim(-0.2, 0.2) +
    ggtitle("Total Difference Score for Learned Shape")
```

Dotplot

```{r}
ggplot(aes(x = training_condition, y = tot_diff_score, fill = training_condition), data = ss) +
    geom_dotplot(binaxis = "y", stackdir = "center") +
    scale_fill_solarized() +
    guides(fill=F)
```

Model 

```{r}
lm1 <- lm(tot_diff_score ~ training_condition, data = ss)
```

### Separate by question

```{r}
ss <- d1 %>% 
    filter(trial_type %in% c("relational","entity")) %>% 
    group_by(subids, training_condition, block, question, trial_type) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest)

ms <- ss %>% 
    group_by(training_condition, question, trial_type) %>% 
    summarise(m = mean(tot_diff_score),
              ci_h = ci.high(tot_diff_score),
              ci_l = ci.low(tot_diff_score))

```

```{r}
ggplot(aes(x = question, y = m, fill = training_condition), data = ms) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m - ci_l, ymax = m + ci_h)) +
    geom_hline(yintercept = 0) +
    facet_grid(trial_type~training_condition) +
    guides(fill=F) +
    scale_fill_solarized() +
    ylim(-0.2, 0.2) +
    ggtitle("Is a Rhombus also a ________?")

```

### Separate by shape tested

```{r}
ss <- d1 %>% 
    filter(trial_type %in% c("relational","entity")) %>% 
    group_by(subids, training_condition, block, shape, trial_type) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest)

ms <- ss %>% 
    group_by(training_condition, shape, trial_type) %>% 
    summarise(m = mean(tot_diff_score),
              ci_h = ci.high(tot_diff_score),
              ci_l = ci.low(tot_diff_score))

```

```{r}
ggplot(aes(x = shape, y = m, fill = training_condition), data = ms) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m - ci_l, ymax = m + ci_h)) +
    geom_hline(yintercept = 0) +
    facet_grid(trial_type~training_condition) +
    guides(fill=F) +
    scale_fill_solarized() +
    ylim(-0.3, 0.3) +
    ggtitle("Click on all of the Rhombuses")

```

### Analysis based on individual ss pretest knowledge of rhombus (entity)

Does your pretest rhombus knowledge predict how you will do at test? 
Do we see condition differences based on pretest rhombus knowledge

```{r}
ss_rh_pretest <- d1 %>% 
    filter(trial_type == "entity", shape == shape_learned |question == shape_learned, 
           block == "pretest") %>% 
    group_by(subids) %>% 
    summarise(num_corr_rh_pre = sum(correct)) %>% 
    mutate(num_corr_rh_pre_fact = cut(num_corr_rh_pre, 4))

# merge with full data frame
d1 <- left_join(d1, ss_rh_pretest, by = "subids")
```

```{r}
ss <- d1 %>% 
    filter(trial_type %in% c("relational","entity")) %>% 
    group_by(subids, training_condition, block, trial_type, num_corr_rh_pre_fact, num_corr_rh_pre) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest)
```

```{r}
ms <- ss %>% 
    group_by(training_condition, num_corr_rh_pre_fact) %>% 
    summarise(m = mean(tot_diff_score),
              ci_h = ci.high(tot_diff_score),
              ci_l = ci.low(tot_diff_score))


ggplot(aes(x = num_corr_rh_pre_fact, y = m, fill = training_condition), data = ms) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m - ci_l, ymax = m + ci_h)) +
    geom_hline(yintercept = 0) +
    facet_grid(.~training_condition) +
    guides(fill=F) +
    scale_fill_solarized() +
    ylim(-0.55, 0.55) 
```


```{r}
ggplot(aes(x = num_corr_rh_pre_fact, y = tot_diff_score, fill = training_condition), data = ss) +
    geom_boxplot() +
    scale_fill_solarized() +
    facet_grid(.~training_condition)
```

### Total difference score analysis

```{r}
ss <- d1 %>% 
    filter(trial_type %in% c("relational","entity"), remove == "no", 
           question == shape_learned | shape == shape_learned) %>% 
    group_by(subids, training_condition, block, trial_type) %>% 
    summarise(m = mean(correct)) %>% 
    spread(key = block, value = m) %>% 
    mutate(tot_diff_score = posttest - pretest) 

ms <- ss %>% 
    group_by(training_condition, trial_type) %>% 
    summarise(m = mean(tot_diff_score),
              ci_h = ci.high(tot_diff_score),
              ci_l = ci.low(tot_diff_score))

ggplot(aes(x = training_condition, y = m, fill = training_condition), data = ms) +
    geom_bar(stat = "identity") +
    geom_linerange(aes(ymin = m - ci_l, ymax = m + ci_h)) +
    geom_hline(yintercept = 0) +
    guides(fill=F) +
    scale_fill_solarized() +
    ylim(-0.35, 0.35) +
    facet_grid(.~trial_type)
```


### Analysis based on evidence given or selected

Munge training data, so we can score them.

```{r}
ss_sampling <- d1 %>% 
    filter(trial_type == "training", experiment == "random_passive", 
           training_condition %in% c("active_active", "passive_passive")) %>% 
    mutate(question_and_shape = paste(shape, question, sep = "_"))

correct <- apply(ss_sampling, 1, flag_correct_trial)
ss_sampling$correct <- NULL

# merge correct info with main df
ss_sampling <- cbind(ss_sampling, correct)
```

Score the training data for each participant

```{r}
ss_sampling 

```